https://arxiv.org/pdf/2403.03432.pdf

 **M**ixture-**o**f-LoR**A** 

解决两个问题：

1.在实际应用场景中，通常存在具有异构和不平衡训练数据的多个具有破坏性的领域任务，以及有限的计算资源。因此，隐式参数融合方法存在相互干扰，导致在领域内任务上模型性能下降，我们通常更关注领域特定LLM的领域专业知识，而不是其泛化性能。

2.MoE机制需要基于新的模型结构和大量训练语料库从头开始训练。集合LLMs需要足够的计算资源同时部署多个独立的LLMs。

~~因为我对MoE一无所知，姑且理解为将不同领域的专家LLM进行合并的过程~~

![image](https://img2024.cnblogs.com/blog/1797571/202403/1797571-20240309174248330-917356139.png)

我们需要训练一个 classifer 来实现找到最适合的 LoRA。论文中的想法是给 corpus 中的 token 一个 label 表示这个内容应该用哪个 LoRA 增强来提升模型性能。这里的训练过程中把 LoRA 和 LLM 的参数冻结之后只训练 Classifer。

这里的分类器是一个监督学习的过程，在训练过程中将一个文段标上同样的 label。在推理的过程中，作者介绍了两种选择 LoRA 的办法，其一是voting，其二是使用上一个 token 分类的 argmax，测试发现后者表现较好。

有几个点需要注意，一旦涉及到分类器，那么这里的LoRA就变成了外挂模块。其次是这个涨点有限。
