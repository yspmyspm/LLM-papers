通过看 arxiv 网址也能看出来这些内容非常古早了

https://aclanthology.org/2020.findings-emnlp.71.pdf 这是使用在 knowledge plugin 中的检索模型，好像。

https://arxiv.org/pdf/2004.05150.pdf 著名 longformer，针对长上下文输入输出

https://arxiv.org/pdf/2104.07012.pdf 著名 sparse attention
